{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import openai\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential, # for exponential backoff\n",
    ")  \n",
    "import wandb\n",
    "from wandb.sdk.data_types.trace_tree import Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get openai API key\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "PROJECT = \"dlai_llm\"\n",
    "WANDB_API_KEY = os.environ['WANDB_API_KEY']\n",
    "\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(\n",
    "    anonymous=\"allow\",\n",
    "\tkey=WANDB_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:mm021pi8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-universe-4</strong> at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/mm021pi8' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/mm021pi8</a><br/> View project at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241113_200958-mm021pi8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:mm021pi8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tauan/Documents/GitHub/coursera-evaluating-and-debugging-generative-ai/laboratory/wandb/run-20241114_111520-r3jxoud9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/r3jxoud9' target=\"_blank\">major-sound-5</a></strong> to <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/r3jxoud9' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/r3jxoud9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=PROJECT, \n",
    "    job_type=\"generation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat import ChatCompletion\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs) -> ChatCompletion:\n",
    "    return openai.chat.completions.create(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb import Table\n",
    "\n",
    "def generate_and_print(\n",
    "        system_prompt:str, \n",
    "        user_prompt:str, \n",
    "        table:Table,\n",
    "        n:int = 5,\n",
    "    ) -> None:\n",
    "    \n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    responses = completion_with_backoff(\n",
    "\t\tn = n,\n",
    "\t\tmodel=MODEL_NAME,\n",
    "\t\tmessages=messages,\n",
    "\t)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    for response in responses.choices:\n",
    "        generation = response.message.content\n",
    "        print(generation)\n",
    "        \n",
    "    table.add_data(\n",
    "\t\tsystem_prompt,\n",
    "\t\tuser_prompt,\n",
    "\t\t[response.message.content for response in responses.choices],\n",
    "\t\telapsed_time,\n",
    "\t\tdatetime.datetime.fromtimestamp(responses.created),\n",
    "\t\tresponses.model,\n",
    "\t\tresponses.usage.prompt_tokens,\n",
    "\t\tresponses.usage.completion_tokens,\n",
    "\t\tresponses.usage.total_tokens\n",
    "\t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a creative copywriter.\n",
    "You're given a category of game asset, \\\n",
    "and your goal is to design a name of that asset.\n",
    "The game is set in a fantasy world \\\n",
    "where everyone laughs and respects each other, \n",
    "while celebrating diversity.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define W&B Table to store generations\n",
    "columns = [\"system_prompt\", \"user_prompt\", \"generations\", \"elapsed_time\", \"timestamp\",\\\n",
    "            \"model\", \"prompt_tokens\", \"completion_tokens\", \"total_tokens\"]\n",
    "table = wandb.Table(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosmic Jester of Infinite Laughter\n",
      "Name: Harmony Quantumflux\n",
      "Name: Amara Spectra\n",
      "Description: Amara Spectra is a quirky and brilliant astrophysicist from the planet Galactica. With her radiant energy and love for all things cosmic, she brings a fresh perspective and a whole lot of laughter to the group. Her passion for learning and her kind heart make her an instant hit with the gang, sparking new adventures and discoveries in every episode.\n",
      "Name: Harmony Gigglesnort\n",
      "Name: Harmony Hilarity\n",
      "Description: A quirky and lovable character who brings a harmonious blend of laughter and wit to The Big Bang Theory group. With her infectious humor and respect for diversity, Harmony Hilarity adds a fresh and entertaining dynamic to the show's already colorful cast of characters.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"A new The Big Bang Theory character\"\n",
    "generate_and_print(system_prompt, user_prompt, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmony Gems\n",
      "Gleaming Harmony Gems\n",
      "Harmony Gems\n",
      "Harmony Gems\n",
      "Sparkle Harmony Gems\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"jewel\"\n",
    "generate_and_print(system_prompt, user_prompt, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-sound-5</strong> at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/r3jxoud9' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/r3jxoud9</a><br/> View project at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241114_111520-r3jxoud9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({\"simple_generations\": table})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Tracer to log more complex chains\n",
    "\n",
    "How can we get more creative outputs? Let's design an LLM chain that will first randomly pick a fantasy world, and then generate character names. We will demonstrate how to use Tracer in such scenario. We will log the inputs and outputs, start and end times, whether the OpenAI call was successful, the token usage, and additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds = [\n",
    "    \"a mystic medieval island inhabited by intelligent and funny frogs\",\n",
    "    \"a modern castle sitting on top of a volcano in a faraway galaxy\",\n",
    "    \"a digital world inhabited by friendly machine learning engineers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your config\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.7\n",
    "system_message = \"\"\"You are a creative copywriter. \n",
    "You're given a category of game asset and a fantasy world.\n",
    "Your goal is to design a name of that asset.\n",
    "Provide the resulting name only, no additional description.\n",
    "Single name, max 3 words output, remember!\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_creative_chain(query:str) -> None:\n",
    "    # part 1 - a chain is started...\n",
    "    start_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "\n",
    "    root_span = Trace(\n",
    "          name=\"MyCreativeChain\",\n",
    "          kind=\"chain\",\n",
    "          start_time_ms=start_time_ms,\n",
    "          metadata={\"user\": \"student_1\"},\n",
    "          model_dict={\"_kind\": \"CreativeChain\"}\n",
    "          )\n",
    "\n",
    "    # part 2 - your chain picks a fantasy world\n",
    "    time.sleep(3)\n",
    "    world = random.choice(worlds)\n",
    "    expanded_prompt = f'Game asset category: {query}; fantasy world description: {world}'\n",
    "    tool_end_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "\n",
    "    # create a Tool span \n",
    "    tool_span = Trace(\n",
    "          name=\"WorldPicker\",\n",
    "          kind=\"tool\",\n",
    "          status_code=\"success\",\n",
    "          start_time_ms=start_time_ms,\n",
    "          end_time_ms=tool_end_time_ms,\n",
    "          inputs={\"input\": query},\n",
    "          outputs={\"result\": expanded_prompt},\n",
    "          model_dict={\"_kind\": \"tool\", \"num_worlds\": len(worlds)}\n",
    "          )\n",
    "\n",
    "    # add the TOOL span as a child of the root\n",
    "    root_span.add_child(tool_span)\n",
    "\n",
    "    # part 3 - the LLMChain calls an OpenAI LLM...\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system_message},\n",
    "      {\"role\": \"user\", \"content\": expanded_prompt}\n",
    "    ]\n",
    "\n",
    "    response = completion_with_backoff(model=model_name,\n",
    "                                       messages=messages,\n",
    "                                       max_tokens=12,\n",
    "                                       temperature=temperature)   \n",
    "\n",
    "    llm_end_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "    response_text = response.choices[0].message.content #[\"choices\"][0][\"message\"][\"content\"]\n",
    "    token_usage = response.usage.to_dict() #[\"usage\"].to_dict()\n",
    "\n",
    "    llm_span = Trace(\n",
    "          name=\"OpenAI\",\n",
    "          kind=\"llm\",\n",
    "          status_code=\"success\",\n",
    "          metadata={\"temperature\":temperature,\n",
    "                    \"token_usage\": token_usage, \n",
    "                    \"model_name\":model_name},\n",
    "          start_time_ms=tool_end_time_ms,\n",
    "          end_time_ms=llm_end_time_ms,\n",
    "          inputs={\"system_prompt\":system_message, \"query\":expanded_prompt},\n",
    "          outputs={\"response\": response_text},\n",
    "          model_dict={\n",
    "              \"_kind\": \"Openai\", \n",
    "              \"engine\": response.model, #[\"model\"], \n",
    "              \"model\": response.object, #[\"object\"]\n",
    "            }\n",
    "          )\n",
    "\n",
    "    # add the LLM span as a child of the Chain span...\n",
    "    root_span.add_child(llm_span)\n",
    "\n",
    "    # update the end time of the Chain span\n",
    "    root_span.add_inputs_and_outputs(\n",
    "          inputs={\"query\":query},\n",
    "          outputs={\"response\": response_text})\n",
    "\n",
    "    # update the Chain span's end time\n",
    "    root_span.end_time_ms = llm_end_time_ms\n",
    "\n",
    "\n",
    "    # part 4 - log all spans to W&B by logging the root span\n",
    "    root_span.log(name=\"creative_trace\")\n",
    "    print(f\"Result: {response_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gq3tur5q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-fog-7</strong> at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/gq3tur5q' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/gq3tur5q</a><br/> View project at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241114_111801-gq3tur5q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gq3tur5q). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tauan/Documents/GitHub/coursera-evaluating-and-debugging-generative-ai/laboratory/wandb/run-20241114_111901-1wapks0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/1wapks0n' target=\"_blank\">noble-hill-8</a></strong> to <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/1wapks0n' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/1wapks0n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/1wapks0n?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x10fab2310>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start a new wandb run\n",
    "wandb.init(project=PROJECT, job_type=\"generation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Pyro Knight\n"
     ]
    }
   ],
   "source": [
    "run_creative_chain(\"hero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Volcano Emberstone\n"
     ]
    }
   ],
   "source": [
    "run_creative_chain(\"jewel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-hill-8</strong> at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/1wapks0n' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/1wapks0n</a><br/> View project at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241114_111901-1wapks0n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain agent\n",
    "\n",
    "In the third scenario, we'll introduce an agent that will use tools such as WorldPicker and NameValidator to come up with the ultimate name. We will also use Langchain here and demonstrate its W&B integration.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tauan/Documents/GitHub/coursera-evaluating-and-debugging-generative-ai/laboratory/wandb/run-20241114_113236-et83qfz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/et83qfz6' target=\"_blank\">dauntless-pine-9</a></strong> to <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/et83qfz6' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/et83qfz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/et83qfz6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x11ea1f850>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT, job_type=\"generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class WorldPickerTool(BaseTool):\n",
    "    name: str = \"pick_world\"\n",
    "    description: str = \"pick a virtual game world for your character or item naming\"\n",
    "    worlds: List[str] = [\n",
    "                \"a mystic medieval island inhabited by intelligent and funny frogs\",\n",
    "                \"a modern anthill featuring a cyber-ant queen and her cyber-ant-workers\",\n",
    "                \"a digital world inhabited by friendly machine learning engineers\"\n",
    "            ]\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        time.sleep(1)\n",
    "        return random.choice(self.worlds)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"pick_world does not support async\")\n",
    "        \n",
    "class NameValidatorTool(BaseTool):\n",
    "    \n",
    "    name: str = \"validate_name\"\n",
    "    description: str = \"validate if the name is properly generated\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        time.sleep(1)\n",
    "        if len(query) < 20:\n",
    "            return f\"This is a correct name: {query}\"\n",
    "        else:\n",
    "            return f\"This name is too long. It should be shorter than 20 characters.\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"validate_name does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/qq7z88g96rl91lrdbj227_r80000gn/T/ipykernel_78233/2004885880.py:2: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "tools = [WorldPickerTool(), NameValidatorTool()]\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/qq7z88g96rl91lrdbj227_r80000gn/T/ipykernel_78233/1240652710.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to pick a virtual game world first and then come up with a hero's name in that world.\n",
      "Action: pick_world\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma digital world inhabited by friendly machine learning engineers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I need to come up with a name for a hero in this virtual world.\n",
      "Action: validate_name\n",
      "Action Input: BraveBot\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis is a correct name: BraveBot\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have a virtual game world called Friendly Machine Learning Engineers and a hero named BraveBot.\n",
      "Final Answer: BraveBot in the virtual world of Friendly Machine Learning Engineers.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'BraveBot in the virtual world of Friendly Machine Learning Engineers.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Find a virtual game world for me and imagine the name of a hero in that world\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should pick a virtual game world first and then come up with a name for a jewel in that world.\n",
      "Action: pick_world\n",
      "Action Input: fantasy RPG world\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma modern anthill featuring a cyber-ant queen and her cyber-ant-workers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThis world has a futuristic twist, so the jewel name should reflect that.\n",
      "Action: validate_name\n",
      "Action Input: Cyber Shard\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis is a correct name: Cyber Shard\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the final name for a jewel in the fantasy RPG world.\n",
      "Final Answer: Cyber Shard\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cyber Shard'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Find a virtual game world for me and imagine the name of a jewel in that world\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to pick a virtual game world first before I can imagine the name of food in it.\n",
      "Action: pick_world\n",
      "Action Input: N/A\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3ma digital world inhabited by friendly machine learning engineers\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have a virtual game world, I can imagine the name of food in it.\n",
      "Action: validate_name\n",
      "Action Input: ByteBites\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThis is a correct name: ByteBites\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: ByteBites in the digital world inhabited by friendly machine learning engineers.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ByteBites in the digital world inhabited by friendly machine learning engineers.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Find a virtual game world for me and imagine the name of food in that world.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-pine-9</strong> at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/et83qfz6' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm/runs/et83qfz6</a><br/> View project at: <a href='https://wandb.ai/tauan-mendes-stefanini/dlai_llm' target=\"_blank\">https://wandb.ai/tauan-mendes-stefanini/dlai_llm</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241114_113236-et83qfz6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
